---
title: "Homework 8"
author: "Ziyang (Bob) Ding"
header-includes:
   - \usepackage{amsmath}
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:  pdf_document
latex_engine: xelatex
mainfont: "Times New Roman"

---

\newcommand*{\argmax}{arg\,max}
\newcommand*{\argmin}{arg\,min}

<style type="text/css">

h1.title {
  font-size: 38px;
  color: DarkRed;
  text-align: center;
}
h4.author { /* Header 4 - and the author and data headers use this too  */
    font-size: 18px;
  font-family: "Times New Roman", Times, serif;
  color: DarkRed;
  text-align: center;
}
h4.date { /* Header 4 - and the author and data headers use this too  */
  font-size: 18px;
  font-family: "Times New Roman", Times, serif;
  color: DarkBlue;
  text-align: center;
}
</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



# Problem 1

**Solve the following by defining an appropriate Markov chain and using first-step analysis:**

* (a) **In repeated (fair) coin tosses:**

  + i. **Calculate the expected number of tosses until 2 successive heads.**

  + ii. **Of the two patterns HHT and HTH, which do you expect to observe first and why.**

* (b) **Rat maze: for a rat located as shown performing a random walk calculate the probability of finding food before exiting.Note that the exit is on the wall, ie the rat can move down 1 step without exiting the maze.**



&nbsp;

**Proof**

* (a) 

  + Denote $f(n)$ as expected step needed from already having $n$ consecutive heads to achieving $2$ consecutive heads. So we are interested in $f(0)$. By Komogorov extension theorem, we have
    \begin{align*}
        f(2) &= 0\\
        f(1) &= 1 + \frac{1}{2}f(2) + \frac{1}{2}f(0) = 1 + \frac{1}{2}f(0) \\
        f(0) &= 1 + \frac{1}{2}f(1) + \frac{1}{2}f(0)
    \end{align*}
    We have that $f(0) = 6$
    
    
  + $HTH$ is going to be faster as if you get $T$ after $H$, you lose everything and have to start from the bottom. However, for $HTH$, if you get $H$ after another $H$, you don't lose anything. The rest of the game is symmetrical so we don't need to worry. Therefore, $HTH$ is faster.


&nbsp;
&nbsp;
&nbsp;

* (b)

I don't like this question, especially in latex: Label the rooms using 1,2,3(food),4(Rat),5,6,7,8(exit). Denote $f(n)$ as probability that $n$ will go to exit and been absorbed before it reaches the food. Therefore, we have:

$$
\begin{aligned}
    f(8) &= 1\\
    f(7) &= \frac{1}{2} + \frac{1}{2}f(4)\\
    f(6) &= \frac{1}{2}f(3) + \frac{1}{2}f(5)\\
    f(5) &= \frac{1}{3}f(2) + \frac{1}{3}f(4) + \frac{1}{3}f(6)\\
    f(4) &= \frac{1}{3}f(1) + \frac{1}{3}f(5) + \frac{1}{3}f(7)\\
    f(3) &= 0\\
    f(2) &= \frac{1}{2}f(1) + \frac{1}{2}f(3) + \frac{1}{3}f(5)\\
    f(1) &= \frac{1}{2}f(2) + \frac{1}{2}f(4)\\
\end{aligned}
$$

Solve for solution. We get the answer

&nbsp;
&nbsp;
&nbsp;
&nbsp;
&nbsp;
&nbsp;


# Problem 2

**Define a Markov chain on $0, \ldots, N$ by:**

$$
\begin{aligned}
P_{i, j}=\left\{\begin{array}{ll}
1 & i=j=0 \\
1 / i & 0 \leq j<i \leq N \\
0 & \text { otherwise }
\end{array}\right.
\end{aligned}
$$

**i.e. from state $j$ the chain is equally likely to go to $0, \ldots, j-1$**

* (a) **Determine the fundamental matrix for the transient states.**

$$
\begin{aligned}
    \sum_{i=1}^\infty G^i&= \begin{bmatrix}
    0  &   0&   0&   0&   0&   0&   0&   0& \dots   0&   0\\
    1/2&   0&   0&   0&   0&   0&   0&   0& \dots   0&   0\\
    1/2& 1/3&   0&   0&   0&   0&   0&   0& \dots   0&   0\\
    1/2& 1/3& 1/4&   0&   0&   0&   0&   0& \dots   0&   0\\
    1/2& 1/3& 1/4& 1/5&   0&   0&   0&   0& \dots   0&   0\\
    1/2& 1/3& 1/4& 1/5& 1/6&   0&   0&   0& \dots   0&   0\\
    1/2& 1/3& 1/4& 1/5& 1/6& 1/7&   0&   0& \dots   0&   0\\
    1/2& 1/3& 1/4& 1/5& 1/6& 1/7& 1/8&   0& \dots   0&   0\\
    \vdots&\vdots&\vdots&\vdots&\vdots&\vdots&\vdots&  \vdots& \ddots   0&   0\\
    1/2& 1/3& 1/4& 1/5& 1/6& 1/7& 1/8&   1/9& \dots   1/n&   0\\
    \end{bmatrix}
\end{aligned}
$$

* (b) **Determine the distribution of the last positive integer visited.**



&nbsp;

**Proof**

* (a)



&nbsp;
&nbsp;
&nbsp;

* (b)




&nbsp;
&nbsp;
&nbsp;
&nbsp;
&nbsp;
&nbsp;


# Problem 3

**Choose one of the above problems (either $1(\mathrm{a})$ ii, $1 \mathrm{b},$ or $2 \mathrm{b}$ ) and validate your results by:**

* (a) **Computing large powers of the transition matrix.**

* (b) **Simulating realizations of the Markov chain.**



&nbsp;

**Proof**

* (a)

&nbsp;
&nbsp;
&nbsp;

* (b)


&nbsp;
&nbsp;
&nbsp;
&nbsp;
&nbsp;
&nbsp;

# Problem 4

**The Gibbs sampler defined in class cycles through coordinates in a fixed order. Alternatively, we may define a random-scan Gibbs sampler, which iteratively chooses $i \in\{1, \ldots, d\}$ at random (according to probabilities $p_{i}$ say), and sets**

$$
\begin{aligned}
\theta^{(n+1)}=\left(\theta_{1}^{(n)}, \ldots, \theta_{i-1}^{(n)}, \theta_{i}^{*}, \theta_{i+1}^{(n)}, \ldots, \theta_{d}^{(n)}\right)
\end{aligned}
$$

with

$$
\begin{aligned}
\theta_{i}^{*} \sim \pi\left(\theta_{i} | \theta_{1}^{(n)}, \ldots, \theta_{i-1}^{(n)}, \theta_{i+1}^{(n)}, \ldots, \theta_{d}^{(n)}\right)
\end{aligned}
$$

* (a) **Show that this also produces a Markov chain with stationary distribution $\pi$**

* (b) **Give sufficient conditions for this chain to have limiting distribution $\pi$**

&nbsp;

**Proof**

* (a)

$$
\pi(\theta_x)P(\theta_x, \theta_y) = \pi(\theta_y)P(\theta_y, \theta_x) 
$$

The chain is reversible. Besides, 
$$
\begin{aligned}
P\left(\theta_{n+1} \in A | \theta_{0}, \ldots, \theta_{n}\right) &=P\left(\theta_{n+1} \in A | \theta_{n}\right) \\
&=\int_{A} K\left(\theta_{n}, d \theta\right)
\end{aligned}
$$

In this way, we know that the chain is memoriless. Therefore, it is a markov chain with distribution $\pi$.

&nbsp;
&nbsp;
&nbsp;


* (b)

By theorem, we need the chain to be $\pi$-invariant, $\pi$-irreducible, aperiodic, and Harris recurrent. To be $\pi$-invariant.

# Problem 5

**The famous "braking data" of Tukey (1977) is available in R under the dataset name cars.
It gives the speeds traveled (mph) and braking distances (feet) for 50 cars. It is thought that
a good model for this dataset is a quadratic model:**

$$
\begin{aligned}
y_{i j}=a+b x_{i}+c x_{i}^{2}+\epsilon_{i j} \quad \text { for } i=1, \ldots, k ; \quad j=1 \ldots, n_{i}
\end{aligned}
$$

* (a) **Write down the likelihood function assuming $\epsilon_{i j} \sim N\left(0, \sigma^{2}\right)$**

*(b) **Obtain estimates of $a, b, c$ and $\sigma^{2}$ from a standard linear regression.**

*(c) **View the likelihood in part (a) as a posterior distribution under flat priors, and construct a Metropolis-Hastings algorithm to sample from it using a Metropolized independence sampler with proposal distributions selected based on your estimates in (b). Use normals for $a, b, c$ and inverse-gamma for $\sigma^{2}$**

*(d) **Make histograms of the posterior distributions of the parameters. Show any plots or diagnostics used to monitor convergence.**

*(e) **Consider robustness by modifying the error distribution to $\epsilon_{i j} \sim t_{4}\left(0, \sigma^{2}\right)$ and re-running your analysis. Do you need to modify your proposal distributions?**

&nbsp;

**Proof**


* (a) 

Denote $X_i$ as aligning $[1, x_{i}, x_{i}^2]$ vertically for $n_i$ times, so we can form $k$ $n_i \times 3$ matricies. Then, we concatenate $X_i$ vertically to form a $X$ as $\sum_{i=1}^k n_i \times 3$ matrix. Similarly, we align all the corresponding $y_{ij}$ vertically, and we get a $\sum_{i=1}^k n_i$ dimensional vector. The likelihood is that

$$
\begin{aligned}
  Y &= X\beta + I\epsilon\\
  \beta &= (a,b,c)^\top\\
  \epsilon &\sim N(0, I\sigma^2)\\
  \mathcal{L}(Y; X,\beta) &= (2\pi)^{-\sum_{i=1}^k n_i /2}\sigma^{-\sum_{i=1}^k n_i} \exp\left\{   -\frac{1}{2}\sigma^{-2\sum_{i=1}^k n_i}  \beta^TX^T X\beta \right\} 
\end{aligned}
$$

&nbsp;
&nbsp;
&nbsp;


* (b) 

$$
(a,b,c) \sim \mathcal{N}\left( (X^TX)^{-1} XY, (X^TX)^{-1} \sigma^2\right)
$$

&nbsp;
&nbsp;
&nbsp;


* (c) 

```{r}
data <- cars
Y <- as.matrix( data$dist )
data$speed2 <- data$speed ^2
data$one <- 1 
columns <- c("one","speed","speed2")
X <- as.matrix(data[columns])

install.packages("rjags") 

```


&nbsp;
&nbsp;
&nbsp;


* (d) 

&nbsp;
&nbsp;
&nbsp;


* (e) 

&nbsp;
&nbsp;
&nbsp;
&nbsp;
&nbsp;
&nbsp;
&nbsp;
&nbsp;
&nbsp;
&nbsp;
&nbsp;
&nbsp;
&nbsp;
&nbsp;
&nbsp;
&nbsp;
&nbsp;
&nbsp;
&nbsp;
&nbsp;
&nbsp;
&nbsp;
&nbsp;
&nbsp;
&nbsp;
&nbsp;
